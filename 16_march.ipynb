{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c155912-ed19-46c0-b9d8-2ab49884ac1e",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2a1b0-1e4f-4713-b03c-b950c41cd38b",
   "metadata": {},
   "source": [
    "Underfit models experience high bias—they give inaccurate results for both the training data and test set, On the other hand, overfit models experience high variance—they give accurate results for the training set but not for the test set.\n",
    "\n",
    "Both of the important factor for the machine learning and their models design, if we have no much quanity of the parameters but we have to predict then we have to use overfiting parameters, other hand we have much data but we need few set of data then we use underfiting models training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00f664-e06e-45ec-b172-fdd879dba0bc",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99056d5d-3e78-489b-81c3-ef3eaf0801de",
   "metadata": {},
   "source": [
    "Overfitting is an undesirable machine learning behavior that occurs when the machine learning model gives accurate predictions for training data but not for new data. When data scientists use machine learning models for making predictions, they first train the model on a known data set. Then, based on this information, the model tries to predict outcomes for new data sets. An overfit model can give inaccurate predictions and cannot perform well for all types of new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e6a1b-37b3-444a-872c-b6b5c7ecf330",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5f32f-c988-48de-8cb4-9abe11143b47",
   "metadata": {},
   "source": [
    "Underfitting is another type of error that occurs when the model cannot determine a meaningful relationship between the input and output data. You get underfit models if they have not trained for the appropriate length of time on a large number of data points.\n",
    "\n",
    "These are the following list:-\n",
    "Data used for training is not cleaned and contains noise (garbage values) in it.\n",
    "The model has a high bias.\n",
    "The size of the training dataset used is not enough.\n",
    "The model is too simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540ced22-ed43-4245-b23a-fe39522758c3",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366848a-f7e3-4fd6-89f1-32b05b543d5b",
   "metadata": {},
   "source": [
    "It is important to understand prediction errors (bias and variance) when it comes to accuracy in any machine-learning algorithm. There is a tradeoff between a model’s ability to minimize bias and variance which is referred to as the best solution for selecting a value of Regularization constant. A proper understanding of these errors would help to avoid the overfitting and underfitting of a data set while training the algorithm. \n",
    "\n",
    "Bias and variance are inversely connected. It is impossible to have an ML model with a low bias and a low variance. When a data engineer modifies the ML algorithm to better fit a given data set, it will lead to low bias—but it will increase variance.\n",
    "\n",
    "t helps optimize the error in our model and keeps it as low as possible. An optimized model will be sensitive to the patterns in our data, but at the same time will be able to generalize to new data. In this, both the bias and variance should be low so as to prevent overfitting and underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a4672-b138-49a8-9f8d-be006aea2cd2",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dd82e9-73a3-4514-aba2-2b9bf7b6d527",
   "metadata": {},
   "source": [
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data.\n",
    "\n",
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c1796e-bf06-4b0a-9411-92a7db1bb507",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6945a1b1-b6bd-4c6c-b214-6700df1951f2",
   "metadata": {},
   "source": [
    "Bias creates consistent errors in the ML model, which represents a simpler ML model that is not suitable for a specific requirement. On the other hand, variance creates variance errors that lead to incorrect predictions seeing trends or data points that do not exist,\n",
    "\n",
    "Algorithm\t    Bias\t            Variance\n",
    "Linear Regression\tHigh Bias\t    Less Variance\n",
    "Decision Tree\t    Low Bias\t     High Variance\n",
    "Bagging\tLow Bias High Variance (Less than Decision Tree)\n",
    "Random Forest\t    Low Bias\t    High Variance (Less than Decision Tree and Bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92263ac-d8d7-4e86-9169-df54449febc2",
   "metadata": {},
   "source": [
    "What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dc4972-59e7-466e-8896-a9393c68094a",
   "metadata": {},
   "source": [
    "Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting. Figure 5: Regularization on an over-fitted model.\n",
    "\n",
    "It is help to prevent the overfiting be the determine the data capacity of the model by mesuring parameters,\n",
    "\n",
    "It involves adding a regularization term to the loss function, which penalizes large weights or complex model architectures. Regularization methods such as L1 and L2 regularization, dropout, and batch normalization help control model complexity and improve its ability to generalize to unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2745c2a0-fac8-496e-8ffc-13574ea37786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
